# -*- coding: utf-8 -*-
"""Salinan dari dicoding_MLOps_Final Task

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K6LTGkyrBzsudKNEdP5bJwWSQzg1JEKj

# Submission 2: Sentimen Analisis Timnas Sepak Bola Indonesia pada Masa Kepelatihan Shin-Tae Young
Nama: Fajar Ramadhan

Username dicoding: fajar_ramadhan_bbk

| | Deskripsi |
| ----------- | ----------- |
| Dataset | [Analisis Sentimen Timnas Sepakbola di Era STY](https://www.kaggle.com/datasets/pajarbebek/analisis-sentimen-timnas-sepakbola-di-era-sty) |
| Masalah | Sepak bola merupakan olahraga paling populer di Indonesia.Supporter sepak bola Indonesia merupakan salah satu supporter terbesar di dunia.
||Saat ini, performa timnas sepak bola Indonesia meningkat tajam sejak kehadiran pelatih kepala Shin-Tae Young.
||Hal ini tak lepas dari beberapa kebijakannya yang cukup berbeda dari pelatih lainnya, seperti naturalisasi hingga pemotongan 2 generasi.
||Hal ini menimbulkan perdebatan di kalangan masyarakat, ada yang mendukung, dan ada pula yang menyayangkannya.
||maka dari itu dibuatkan sebuah pemodelan untuk melakukan analisis sentimen terhadap komentar masyarakat pada media sosial X|
| Solusi machine learning | Membuat sebuah model yang dapat mengetahui sentimen masyakarakat lewat komentar. Hal ini dapat dimanfaatkan
|| bagi *stakeholder* yang terlibat dalam timnas sepakbola untuk mengambil keputusan tentang perpanjangan kontrak kepala pelatih STY.
| Metode pengolahan | Data diolah pada komponen transform dan trainer dengan cara membersihkan komentar dari noise seperti perubahan huruf besar menjadi huruf kecil, serta penghapusan punctuation. Lalu label juga diubah dalam tipe tensor agar dapat diproses oleh pipeline. |
| Arsitektur model | model terdiri dari beberapa layer dengan tugas berbeda, seperti layer pertama terdapat layer TextVectorization untuk mengubah string menjadi bentuk numerik, lalu dilanjut dengan embedding, global average pooling, serta dense |
| Metrik evaluasi | metrik yang digunakan yaitu *Area Under Curve*, *False Positive* dan *Negative*, *True Positive* dan *Negative,* *Binary Accuracy*, serta *binary crossentropy*|
| Performa model | Model yang dilatih mendapatkan hasil yang baik dengan persentase binary accuracy 95% dengan total data validasi (*example count*) 76. Namun, jika ditinjau dari hasil evaluasi
|| masih dibutuhkan peningkatan kualitas model. Pada metriks seperti AUC, *false negative*, dan *binary accuracy* dinilai masih kurang baik. Nilai AUC tidak lebih dari 0.6, yang artinya performa model masih mendekati model random guessing
|| Lalu pada *binary Accuracy* nilai yang dihasilkan juga tidak lebih dari 0.5, serta jumlah *false negative* yang sama *true negatif*, yaitu 23. Sedangkan untuk nilai *false positive* mendapat 11 dan *true positive* mendapat 19, yang artinya
|| model lebih banyak memprediksi nilai yang benar. Terakhir, untuk nilai *binary crossentropy* mendapatkan nilai 1.39626  
| Opsi deployment | Proyek ini di deploy menggunakan Railway App, yaitu salah satu platform yang menyediakan layanan deploy proyek termasuk model machine learning secara gratis |
| Web app |  dapat diakses disini: https://analisis-sentimen-sty-production-ab80.up.railway.app/v1/models/sentimen-analysis-sty-model/metadata |
| Monitoring| Monitoring dilakukan menggunakan Prometheus. Salah satu hal yang dapat dimonitoring adalah *request count* untuk mengetahui jumlah *request* |

# Persiapan Data
"""

import pandas as pd

df = pd.read_csv('/content/deploy_monitoring_model/data/Analisis_sentimen_timnas_sepakbola_indonesia_di_era_STY.csv')
df.head()

df['label']=[1 if label=='positif' else 0 for label in df['label']]

import os

folder = '/content/deploy_monitoring_model/final_data/'
os.makedirs(folder, exist_ok=True)
df.to_csv(folder + 'data.csv', index=False, header=True)

"""# Persiapan

Lingkungan google colab secara otomatis telah menginstall beberapa paket. Maka dari itu kali ini hanya paket yang tidak tersedia saja yang diinstall.
"""

!pip install tfx

import os
import sys
from typing import Text

import tensorflow as tf
import tensorflow_model_analysis as tfma
from tfx.components import (
    CsvExampleGen,
    StatisticsGen,
    SchemaGen,
    ExampleValidator,
    Transform,
    Trainer,
    Evaluator,
    Pusher
)
from tfx.proto import example_gen_pb2, trainer_pb2, pusher_pb2
from tfx.types import Channel
from tfx.dsl.components.common.resolver import Resolver
from tfx.types.standard_artifacts import Model, ModelBlessing
from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import (
    LatestBlessedModelStrategy)

from absl import logging
from tfx.orchestration import metadata, pipeline
from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner

"""# Inisialisasi"""

PIPELINE_NAME = 'fajar_ramadhan_bbk-pipeline'

DATA_ROOT = '/content/deploy_monitoring_model/final_data'
TRANSFORM_MODULE_FILE = '/content/deploy_monitoring_model/modules/sentimen_analysis_sty_transform.py'
TRAINER_MODULE_FILE = '/content/deploy_monitoring_model/modules/sentimen_analysis_sty_trainer.py'

OUTPUT_BASE = '/content/deploy_monitoring_model/outputs'

SERVING_MODEL_DIR = os.path.join(OUTPUT_BASE, 'serving_model')
PIPELINE_ROOT = os.path.join(OUTPUT_BASE, PIPELINE_NAME)
METADATA_PATH = os.path.join(PIPELINE_ROOT, 'metadata.sqlite')

"""Initiate tfx pipeline components
"""
def init_components(
    data_dir,
    transform_module,
    training_module,
    training_steps,
    eval_steps,
    serving_model_dir,
):
    """Initiate tfx pipeline components

    Args:
        data_dir (str): a path to the data
        transform_module (str): a path to the transform_module
        training_module (str): a path to the transform_module
        training_steps (int): number of training steps
        eval_steps (int): number of eval steps
        serving_model_dir (str): a path to the serving model directory

    Returns:
        TFX components
    """
    output = example_gen_pb2.Output(
        split_config = example_gen_pb2.SplitConfig(splits=[
            example_gen_pb2.SplitConfig.Split(name="train", hash_buckets=8),
            example_gen_pb2.SplitConfig.Split(name="eval", hash_buckets=2)
        ])
    )

    example_gen = CsvExampleGen(
        input_base=data_dir,
        output_config=output
    )

    statistics_gen = StatisticsGen(
        examples=example_gen.outputs["examples"]
    )

    schema_gen = SchemaGen(
        statistics=statistics_gen.outputs["statistics"]
    )

    example_validator = ExampleValidator(
        statistics=statistics_gen.outputs['statistics'],
        schema=schema_gen.outputs['schema']
    )

    transform = Transform(
        examples=example_gen.outputs['examples'],
        schema=schema_gen.outputs['schema'],
        module_file=os.path.abspath(transform_module)
    )

    trainer  = Trainer(
        module_file=os.path.abspath(training_module),
        examples=transform.outputs['transformed_examples'],
        transform_graph=transform.outputs['transform_graph'],
        schema=schema_gen.outputs['schema'],
        train_args=trainer_pb2.TrainArgs(
            splits=['train'],
            num_steps=training_steps),
        eval_args=trainer_pb2.EvalArgs(
            splits=['eval'],
            num_steps=eval_steps)
    )

    model_resolver = Resolver(
        strategy_class= LatestBlessedModelStrategy,
        model = Channel(type=Model),
        model_blessing = Channel(type=ModelBlessing)
    ).with_id('Latest_blessed_model_resolver')

    slicing_specs=[
        tfma.SlicingSpec(),
        tfma.SlicingSpec(feature_keys=["komentar"])
    ]

    metrics_specs = [
        tfma.MetricsSpec(metrics=[
                tfma.MetricConfig(class_name='ExampleCount'),
                tfma.MetricConfig(class_name='AUC'),
                tfma.MetricConfig(class_name='FalsePositives'),
                tfma.MetricConfig(class_name='TruePositives'),
                tfma.MetricConfig(class_name='FalseNegatives'),
                tfma.MetricConfig(class_name='TrueNegatives'),
                tfma.MetricConfig(class_name='BinaryAccuracy',
                    threshold=tfma.MetricThreshold(
                        value_threshold=tfma.GenericValueThreshold(
                            lower_bound={'value':0.5}),
                        change_threshold=tfma.GenericChangeThreshold(
                            direction=tfma.MetricDirection.HIGHER_IS_BETTER,
                            absolute={'value':0.0001})
                        )
                )
            ])
    ]

    eval_config = tfma.EvalConfig(
        model_specs=[tfma.ModelSpec(label_key='label')],
        slicing_specs=slicing_specs,
        metrics_specs=metrics_specs
    )

    evaluator = Evaluator(
        examples=example_gen.outputs['examples'],
        model=trainer.outputs['model'],
        baseline_model=model_resolver.outputs['model'],
        eval_config=eval_config)

    pusher = Pusher(
        model=trainer.outputs["model"],
        model_blessing=evaluator.outputs["blessing"],
        push_destination=pusher_pb2.PushDestination(
            filesystem=pusher_pb2.PushDestination.Filesystem(
                base_directory=serving_model_dir
            )
        ),
    )

    components = (
        example_gen,
        statistics_gen,
        schema_gen,
        example_validator,
        transform,
        trainer,
        model_resolver,
        evaluator,
        pusher
    )

    return components

def init_local_pipeline(
    components, pipeline_root: Text
) -> pipeline.Pipeline:

    logging.info(f"Pipeline root set to: {PIPELINE_ROOT}")
    beam_args = [
        "--direct_running_mode=multi_processing"
        # 0 auto-detect based on on the number of CPUs available
        # during execution time.
        "----direct_num_workers=0"
    ]

    return pipeline.Pipeline(
        pipeline_name=PIPELINE_NAME,
        pipeline_root=PIPELINE_ROOT,
        components=components,
        enable_cache=True,
        metadata_connection_config=metadata.sqlite_metadata_connection_config(
            METADATA_PATH
        ),
        beam_pipeline_args=beam_args
    )

if __name__ == "__main__":
    logging.set_verbosity(logging.INFO)

    components = init_components(
        DATA_ROOT,
        training_module=TRAINER_MODULE_FILE,
        transform_module=TRANSFORM_MODULE_FILE,
        training_steps=8,
        eval_steps=8,
        serving_model_dir=SERVING_MODEL_DIR,
    )

    pipeline = init_local_pipeline(components, PIPELINE_ROOT)
    BeamDagRunner().run(pipeline=pipeline)